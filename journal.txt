2011-10-19

Started developing the kernel with the tutorial at http://wiki.osdev.org/Bare_bones
Decided to create ISO images for testing with Bochs.
The code for doing this can be found in the Makefile.
Developed two functions for printing strings and numbers in hex.
These functions were inspired by the tutorial at http://www.jamesmolloy.co.uk/tutorial_html/3.-The%20Screen.html

2011-10-20

Performed gymnastics trying to get GRUB2 to work.
I agree with http://wiki.osdev.org/GRUB_2 that GRUB2 changed their interface.
Added code to display a message and halt when there is multiboot error.
Added code to halt the processor at the end of the kernel.
Decided to use a higher-half kernel using the GDT trick described at http://wiki.osdev.org/Higher_Half_With_GDT
Switch to the NASM assembler because most of the examples I've found used NASM.
Most of the development time was spent looking up magic numbers.

2011-10-21

I'm currently using the Bochs simulator to test the kernel.
As I complete different pieces, I'll test using a physical machine to eliminate the difference between theory and practice.
Added an entry to /etc/grub.d/40_custom and copied the kernel to /boot.
Comment out the GRUB_HIDDEN_TIMEOUT variable in /etc/default/grub to make the boot menu appear.  (I'm using Ubuntu 10.04.)
The test using the physical machine was successful.
The following page describes x86 descriptor types: http://codewiki.wikispaces.com/x86+descriptor+types
First implementation of interrupts/traps.
Test on physical machine was successful.

2011-10-22

Added support for the programmable interrupt timer using code from http://www.jamesmolloy.co.uk/tutorial_html/5.-IRQs%20and%20the%20PIT.html and http://en.wikipedia.org/wiki/Intel_8253.
Test on physical machine was successful.

2011-10-23

Generalize interrupt handling.
Started parsing the multiboot header.
Wrote functions for extending the identity memory map.

2011-10-24

Wrote primitive page fault handler to debug extending the identity map.
Parsed the memory map provided by GRUB.
Test on physical machine was successful.

2011-10-25

Added a kassert macro to help debug and communicate assumptions.
Changed framebuffer to work before and after paging/GDT.
Added assertions related to identity mapping for memory management.
Test on physical machine was successful.
Setting an interrupt handler now changes the masks on the PICs.
Implemented a placement allocator.
Preliminary implemented of a manager for frames (physical pages).
Test on physical machine was successful.

2011-10-26

Fixed interrupt mask bug.
Refactored paging code.
Starting work on heap allocator.

2011-10-27

Finished heap allocator.
Test on a physical machine was successful.

2011-10-28

Implemented a basic hash map.
Kernel is mapped in all address spaces.

2011-10-29

Refactored descriptors.
I'm starting to think seriously about user-mode, automata, etc.
One observation is that the system needs a total of two stacks: one for the kernel to use for interrupts and one for user automata.
Since all context is stored in the state of the automaton, the same stack can be shared by all automata.

2011-10-30

An automaton resembles a libary.
The key question is how to dispatch into the automaton to execution actions.
One way is to dispatch directly, i.e., set the instruction pointer to the beginning of the code for an action.
The parameter associated with an action would be placed in registers.
To make composition safe, we would need a table of some kind that describes the valid entry points.
Another way is to dispatch indirectly by jumping to the same entry point but providing an action number in a register that the dispatching function could then translate into an appropriate offset.
Again, we would need a table describing the valid action numbers.
Direct dispatch is probably more efficient while indirect dispatch provides a level of indirection that makes composition easier.
Continuing this idea, suppose that every automaton provided the following tables:
1.  A table that translates from action number to entry point.
2.  A table that translates from action name to action number.
3.  A table that translates from action number to action name.
We could then do composition based on name which creates a number of possibilities like type checking a composition.
Based on this, I'm going to research if ELF symbol tables can support such features.

2011-10-31

Interrupts will only interact with the scheduler.
They will not be allowed to allocate memory.
Added a user stack to the kernel page directory.
After looking into ELF, I think I will write a post-processor to create the necessary tables in an object file that can be linked with the executable.
Implemented a simple automata set, FIFO scheduler, and system call interface.
Simulating an automaton that counts to 10 and stops was successful on a physical machine.
The next step will be to refactor the automaton to abstract the reusable parts.
My checkpoints going forward are:
1.  Refactor the count-to-ten automaton.
    Goal:  Polish syscall interface and start user-mode scheduler.
2.  Implement producer->consumer.
    The value will be transferred by register.
    Goal:  Composition.
3.  Implement producer->consumer->console.
    The value between consumer and console will be transferred by a buffer.
    Goal:  Implement buffers.

After this, the big goal is to implement the following composition:

+--------+
|  Init  |
+--------+
     ^
     |
     v
+--------+       +--------+
|   VFS  |<----->| System |
+--------+       +--------+
     ^
     |
     v
+--------+
| Initrd |
+--------+

The Init automaton will use the VFS and Initrd to load another another automaton (Init2?) that will bootstrap the rest of the system.
The Initrd can contain hardware drivers, system services, user apps. etc.
Later on, it will probably only contain the necessary drivers to read physical disks and file systems.

Also, I plan to implement 16 IRQ automata, each with a single output.
The associated interrupt just schedules the appropriate output.

2011-11-01

Polished the count_to_ten automaton by creating a user-mode scheduler and a macro for defining unparameterized internal actions.
More macros will follow as I need them.
Implemented producer and consumer.
Test on a physical machine was successful.

2011-11-02

To implement buffers, I need to refactor the frame allocation system and memory management.
This led me to do some reading where I found the following design decisions:
1.  Should the kernel be mapped in all address spaces?
    Yes.  This makes transferring from user-to-kernel more efficient since the segments and TLB are preserved.  It also makes transferring data into the kernel easier.
    No.  The kernel and user processes can have a big virtual address space.  The width of the kernel and processes can be different, e.g., 32-bit kernel and 64-bit processes.
2.  Should the kernel be identity (or offset) mapped?  (The offset is to use virtual memory.)
    Yes.  It makes dealing with hardware easier since there is no address translation.
    No.  It makes dealing with software harder due to manual address translation.  It is also more efficient since segments don't need to be change when switch to/from the kernel.

Based on this, I affirm my decision to map the kernel in all address spaces using virtual memory.

Today, I removed the GDT trick and enabled paging on boot.
I'm currently refactoring the memory manager.

2011-11-03

Linux uses the buddy algorithm to allocate frames.
It defines three zones: DMA, NORMAL, and HIGH.
The HIGH zone is not important.
The DMA zone includes memory below 16M for doing DMA with ISA devices.
The NORMAL zone includes memory above 16M.
The Linux kernel does not use virtual memory, thus, allocations must be contiguous in physical memory.
Consequently, the buddy system is the write choice for Linux because it allocates and coalesces contiguous memory efficiently.

Since Lily uses virtual memory in the kernel, physical allocations do not need to be contiguous except for DMA.
Thus, I will retain the DMA and NORMAL zones of Linux and use the buddy algorithm for DMA.
The NORMAL zone will use a simpler algorithm until there is a good reason to use something more complex.
The algorithm will use an array where each element corresponds to a frame.
A frame is either USED or FREE.
All of the FREE frames form a singly linked list that can be used to allocate or free a frame in O(1) time.
I believe this may be called a stack allocator but I'm not for certain.

When the kernel boots, it maps the first 4M of memory and engages virtual memory.
(The GDT trick is gone.)
It then initializes the global descriptor table (GDT) and interrupt descriptor table (IDT).
It then initializes the frame manager which allocates physical memory.
The frame manager allocates a data structure for each frame and this might exceed the 4M limit on machines with a lot of memory.
(The allocation routine checks for this.)
The frame manager reserves frames below 16M for DMA but will cut into this when no normal frames are free.
To be useful, this either requires a contiguous memory allocator like the buddy algorithm.
Once the frame manager is initialize, the virtual memory manager is initialized.
The virtual memory manager uses a new page directory and page table.
The virtual memory manager uses the frame manager to expand the logical address space of the kernel.
Various allocators can be built using this feature of the virtual memory manager.

I did use a neat trick where page descriptors are mapped to themselves.
All of the page tables for a memory space appear at 0xFFC00000 with the last one being the page directory.
The memory layout from bottom to top is:

0x00000000-0x00100000 Low memory for I/O
 
0xC0000000-0xC0100000 Low memory for I/O (Set by KERNEL_VIRTUAL_BASE et. al)
0xC0100000-?	      Hole from setup
		      Kernel code, data, stack
		      Hole from GRUB data structures
		      Frame manager data structures
		      Heap
	  ...
0xFFC00000-0xFFFFFFFF Page tables and page directory

The kernel code and data contains a stack which I plan to relocate at 0xFFC00000.
The frame for the stack in the kernel can be reclaimed once moved.

I had originally plan to have all automata share a stack.
However, this creates a potential security problem if the stack isn't scrubbed between uses.
Thus, the two choices are:
1.  Give every automaton a private stack.
    The cost in memory is proportional to the number of automata.
    The cost in time is loading a different stack for every action.
2.  Share a common stack.
    The cost in memory is constant.
    The cost in time is scrubbing the stack for every action.

Given the nature of I/O automata, I feel like most stacks will be small but this is a good question to study empirically.
In order for the second choice to be better, a processor must be able to clear the stack faster than caching.
Actually, this brings up an interesting point since an automaton will always write to the cache before reading it.
An automaton will only suffer a cache miss on a stack if enough data has been moved to evict the stack pages from the cache.

Automata do have an interesting property in that the stack is alway assumed to be empty when an action is executed.
Since the stack is a scratchpad, it is safe to steal frames used for a stack.
One could possibly use a watermark to reclaim unused frames.
    
2011-11-04

Started overhauling the memory subsystems.

2011-11-05

The frame manager ignores memory below 1M, reserves memory below 16M for DMA, and places all other memory in a normal zone.
Running the code on a machine with 4G+ is undefined.
The stack allocator keeps a 15-bit reference count so a frame can be shared 32,767 times.
I think this is reasonable as I expect the number of automata in a system to be in the hundreds.

2011-11-07

Tried to isolate multiboot parsing to a few modules.
Decided to simplify the frame manager by eliminating zones.
If the need arises, the interface for the frame manager can be expanded and the implmentation changed accordingly.

2011-11-08

Preliminary implementation of memory maps for automata.
Preliminary implementation of a memory allocator.
Test of the system automaton acting as a counter was successful on a physical machine.

2011-11-09

The allocator used by the system automaton is passed to the various modules that need it.
The goal of the day is to give the system automaton (and every other automaton) a stack and their own address space.
I wrote previously on the rationale behind each automaton receiving a private stack versus and shared global stack.
Basically, I believe that the cost of giving each automaton a stack is less that the cost of scrubbing the stack between each action.
The setrlimit/getrlimit calls can be used to manipulate the stack in Linux.

2011-11-10

Can switch between two automata in different address spaces.
Ran into the same bug twice whose symptom is a triple fault.
The problem was that the stack did not exist or was not valid when switch paging directories.
The solution I adopted is to have a small, dedicated piece of memory in the kernel to use when switching page directories.
I call it a switching stack.
To execute an action in an automaton, I first copy the stack to the switching stack, change to the switch stack, change page directories, etc.
Since the switching stack exists in all address spaces, switching to a different page directory doesn't result in a bad stack.

For my productivity, I believe I'm going to switch to C++.
Basically, I'm tired of writing the same code and algorithms for lists but refuse to make a generic non-type safe implementation.
Thus, C++ seems like the way to go.
Started conversion to C++ objects with automaton.
Introduced frames, logical address, and physical addresses.
Also introduced a bug that I think is related to stack switching.

2011-11-11

Bug was related to stack switch.  Fixed.

2011-11-17

Over the past week I've been converting code to objects.
I've also been working on a subset of the Standard Template Libary to make development easier.

2011-12-01

So its been a while since I written anything.
Mainly because I've gone through a number of iterations restructuring the code.
Here are some observations:
(1) The notion of a singleton object, perhaps implemented as a class with static members, is appealing because there are many singleton objects.
(2) The order in which these singleton objects is initialized is important, i.e., some systems depend on other systems.
(3) Static objects should be treated as being initialized in random order.  This is the nature of C++.  The lesson to be learned is that static initializers should be written assuming that nothing else is initialized.
Based on these observations, one might manually initialize static objects using static methods.  This solves the ordering problem.  I used this idea for the exception_handler, trap_handler, and irq_handler.
(4) STL containers can only be initialized after dynamic memory is functioning.  Consequently, singleton objects with STL contains and static initializers are out because one cannot assume that dynamic memory is functioning when their initializer is called.
But, we'd still like to declare these objects "statically".
What we need is a way to control the order in which the constructors are called.
The solution is to declare all of these objects are members of a single static object in the order in which they should be constructed.
Thus, they are declared statically but initialized in a fixed order.
I used this technique in the kernel object since the frame_allocator uses an STL container.

The boot process now looks like:
--random static initialization--
kernel ()
--more random static initialization--
kmain ()
 -> system_automaton::run
    deferred static initialization
    initialize dynamic memory
    ...

system_automaton::run performs the rather tricky task of bootstrapping dynamic memory.
The dynamic memory system is obvious built on the virtual memory system.
There is only one way to allocate memory from the virtual memory manager and that is using a system call (software interrupt).
When the interrupt fires, it looks up the currently running automaton and uses its memory map to fulfill the request.
The scheduler keeps track of the currently running automaton.
However, the scheduler requires dynamic memory for its initialization.
To break the circular dependency, the system_automaton intercepts requests for allocations and page faults until all systems are adquately initialized and then cuts over to normal operation.

My next goal is to implement the following stack:

+---------+
|   VFS   |
+---------+
     ^
     |
     v
+---------+
|  ext2   |
+---------+
     ^
     |
     v
+---------+
| ramdisk |
+---------+

This will require buffers which is the immediate next order of business.



Take out page scrub in page_handler.
Implement a better allocator.
Memory alignment.
